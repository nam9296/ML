{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(2.)\n",
    "\n",
    "def f(w):\n",
    "    y = w**2\n",
    "    z = 2*y + 5\n",
    "    return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=float32, numpy=8.0>]\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z = f(w)\n",
    "\n",
    "gradients = tape.gradient(z, [w])\n",
    "print(gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선형 회귀 모델 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(4.0)\n",
    "b = tf.Variable(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가설함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def hypothesis(x):\n",
    "    return W*x + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [3.5, 5, 5.5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([15., 21., 23., 25.], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xdata를 가설함수에 전달 -> 예측값 추출\n",
    "hypothesis(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용함수\n",
    "@tf.function\n",
    "def mse_loss(y_pred, y):\n",
    "  # 두 개의 차이값을 제곱을 해서 평균을 취한다.\n",
    "  return tf.reduce_mean(tf.square(y_pred - y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[1,2,3,4,5,6,7,8,9] # 공부하는 시간\n",
    "y=[11,22,33,44,53,66,77,87,95] # 각 공부하는 시간에 맵핑되는 성적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.SGD(0.01)\n",
    "# alpha(learning rate)\n",
    "# W = W - lpha * cost 함수를 w로 미분한 미분계수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   0 | W의 값 : 8.2133 | b의 값 : 1.664 | cost : 1402.555542\n",
      "epoch :  10 | W의 값 : 10.4971 | b의 값 : 1.977 | cost : 1.351182\n",
      "epoch :  20 | W의 값 : 10.5047 | b의 값 :  1.93 | cost : 1.328165\n",
      "epoch :  30 | W의 값 : 10.5119 | b의 값 : 1.884 | cost : 1.306967\n",
      "epoch :  40 | W의 값 : 10.5188 | b의 값 : 1.841 | cost : 1.287436\n",
      "epoch :  50 | W의 값 : 10.5254 | b의 값 : 1.799 | cost : 1.269459\n",
      "epoch :  60 | W의 값 : 10.5318 | b의 값 : 1.759 | cost : 1.252898\n",
      "epoch :  70 | W의 값 : 10.5379 | b의 값 : 1.721 | cost : 1.237644\n",
      "epoch :  80 | W의 값 : 10.5438 | b의 값 : 1.684 | cost : 1.223598\n",
      "epoch :  90 | W의 값 : 10.5494 | b의 값 : 1.648 | cost : 1.210658\n",
      "epoch : 100 | W의 값 : 10.5548 | b의 값 : 1.614 | cost : 1.198740\n",
      "epoch : 110 | W의 값 : 10.5600 | b의 값 : 1.582 | cost : 1.187767\n",
      "epoch : 120 | W의 값 : 10.5650 | b의 값 :  1.55 | cost : 1.177665\n",
      "epoch : 130 | W의 값 : 10.5697 | b의 값 :  1.52 | cost : 1.168354\n",
      "epoch : 140 | W의 값 : 10.5743 | b의 값 : 1.492 | cost : 1.159782\n",
      "epoch : 150 | W의 값 : 10.5787 | b의 값 : 1.464 | cost : 1.151890\n",
      "epoch : 160 | W의 값 : 10.5829 | b의 값 : 1.437 | cost : 1.144619\n",
      "epoch : 170 | W의 값 : 10.5870 | b의 값 : 1.412 | cost : 1.137924\n",
      "epoch : 180 | W의 값 : 10.5909 | b의 값 : 1.387 | cost : 1.131752\n",
      "epoch : 190 | W의 값 : 10.5946 | b의 값 : 1.364 | cost : 1.126073\n",
      "epoch : 200 | W의 값 : 10.5982 | b의 값 : 1.341 | cost : 1.120843\n",
      "epoch : 210 | W의 값 : 10.6016 | b의 값 :  1.32 | cost : 1.116026\n",
      "epoch : 220 | W의 값 : 10.6049 | b의 값 : 1.299 | cost : 1.111589\n",
      "epoch : 230 | W의 값 : 10.6081 | b의 값 : 1.279 | cost : 1.107504\n",
      "epoch : 240 | W의 값 : 10.6111 | b의 값 :  1.26 | cost : 1.103736\n",
      "epoch : 250 | W의 값 : 10.6140 | b의 값 : 1.242 | cost : 1.100273\n",
      "epoch : 260 | W의 값 : 10.6168 | b의 값 : 1.224 | cost : 1.097082\n",
      "epoch : 270 | W의 값 : 10.6195 | b의 값 : 1.207 | cost : 1.094143\n",
      "epoch : 280 | W의 값 : 10.6221 | b의 값 : 1.191 | cost : 1.091434\n",
      "epoch : 290 | W의 값 : 10.6245 | b의 값 : 1.176 | cost : 1.088940\n",
      "epoch : 300 | W의 값 : 10.6269 | b의 값 : 1.161 | cost : 1.086645\n"
     ]
    }
   ],
   "source": [
    "for i in range(301):\n",
    "  with tf.GradientTape() as tape:\n",
    "    # 현재 파라미터에 기반한 입력 x에 대한 예측값을 y_pred\n",
    "    y_pred = hypothesis(X)\n",
    "\n",
    "    # 평균 제곱 오차를 계산\n",
    "    cost = mse_loss(y_pred, y)\n",
    "\n",
    "  # 손실 함수에 대한 파라미터의 미분값 계산\n",
    "  gradients = tape.gradient(cost, [W, b])\n",
    "\n",
    "  # 파라미터 업데이트\n",
    "  optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "\n",
    "  if i % 10 == 0:\n",
    "    print(\"epoch : {:3} | W의 값 : {:5.4f} | b의 값 : {:5.4} | cost : {:5.6f}\".format(i, W.numpy(), b.numpy(), cost))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras로 선형회귀 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(1, input_dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 400.7681 - mse: 400.7681\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.3397 - mse: 2.3397\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.3325 - mse: 2.3325\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 777us/step - loss: 2.3255 - mse: 2.3255\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.3188 - mse: 2.3188\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.3124 - mse: 2.3124\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.3062 - mse: 2.3062\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.3003 - mse: 2.3003\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.2946 - mse: 2.2946\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2892 - mse: 2.2892\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 998us/step - loss: 2.2839 - mse: 2.2839\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 883us/step - loss: 2.2789 - mse: 2.2789\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.2741 - mse: 2.2741\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2694 - mse: 2.2694\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 891us/step - loss: 2.2650 - mse: 2.2650\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.2607 - mse: 2.2607\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 995us/step - loss: 2.2566 - mse: 2.2566\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2526 - mse: 2.2526\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 891us/step - loss: 2.2488 - mse: 2.2488\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 664us/step - loss: 2.2451 - mse: 2.2451\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2416 - mse: 2.2416\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 2.2382 - mse: 2.2382\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2349 - mse: 2.2349\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.2318 - mse: 2.2318\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2287 - mse: 2.2287\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.2258 - mse: 2.2258\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.2230 - mse: 2.2230\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 774us/step - loss: 2.2203 - mse: 2.2203\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.2177 - mse: 2.2177\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.2152 - mse: 2.2152\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.2128 - mse: 2.2128\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.2105 - mse: 2.2105\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2082 - mse: 2.2082\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.2061 - mse: 2.2061\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.2040 - mse: 2.2040\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2020 - mse: 2.2020\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.2000 - mse: 2.2000\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1982 - mse: 2.1982\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1964 - mse: 2.1964\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 2.1946 - mse: 2.1946\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1930 - mse: 2.1930\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1914 - mse: 2.1914\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1898 - mse: 2.1898\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1883 - mse: 2.1883\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1869 - mse: 2.1869\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 666us/step - loss: 2.1855 - mse: 2.1855\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1841 - mse: 2.1841\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1828 - mse: 2.1828\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1816 - mse: 2.1816\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1804 - mse: 2.1804\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 2.1792 - mse: 2.1792\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 778us/step - loss: 2.1781 - mse: 2.1781\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 2.1770 - mse: 2.1770\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1759 - mse: 2.1759\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1749 - mse: 2.1749\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1739 - mse: 2.1739\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1730 - mse: 2.1730\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1721 - mse: 2.1721\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 996us/step - loss: 2.1712 - mse: 2.1712\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 2.1704 - mse: 2.1704\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 883us/step - loss: 2.1695 - mse: 2.1695\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 756us/step - loss: 2.1687 - mse: 2.1687\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1680 - mse: 2.1680\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1672 - mse: 2.1672\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 2.1665 - mse: 2.1665\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1658 - mse: 2.1658\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1652 - mse: 2.1652\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1645 - mse: 2.1645\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1639 - mse: 2.1639\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1633 - mse: 2.1633\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 883us/step - loss: 2.1627 - mse: 2.1627\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 831us/step - loss: 2.1622 - mse: 2.1622\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1616 - mse: 2.1616\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1611 - mse: 2.1611\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1606 - mse: 2.1606\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1601 - mse: 2.1601\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 664us/step - loss: 2.1597 - mse: 2.1597\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 2.1592 - mse: 2.1592\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1588 - mse: 2.1588\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1583 - mse: 2.1583\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1579 - mse: 2.1579\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1575 - mse: 2.1575\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 2.1571 - mse: 2.1571\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1568 - mse: 2.1568\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1564 - mse: 2.1564\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1561 - mse: 2.1561\n",
      "Epoch 87/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 665us/step - loss: 2.1557 - mse: 2.1557\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1554 - mse: 2.1554\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1551 - mse: 2.1551\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 996us/step - loss: 2.1548 - mse: 2.1548\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 698us/step - loss: 2.1545 - mse: 2.1545\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1542 - mse: 2.1542\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 664us/step - loss: 2.1540 - mse: 2.1540\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 914us/step - loss: 2.1537 - mse: 2.1537\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1534 - mse: 2.1534\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1532 - mse: 2.1532\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 906us/step - loss: 2.1529 - mse: 2.1529\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 996us/step - loss: 2.1527 - mse: 2.1527\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1525 - mse: 2.1525\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1523 - mse: 2.1523\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1521 - mse: 2.1521\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1519 - mse: 2.1519\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1517 - mse: 2.1517\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1515 - mse: 2.1515\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1513 - mse: 2.1513\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 2.1511 - mse: 2.1511\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 894us/step - loss: 2.1510 - mse: 2.1510\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1508 - mse: 2.1508\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1506 - mse: 2.1506\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 2.1505 - mse: 2.1505\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1503 - mse: 2.1503\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1502 - mse: 2.1502\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1501 - mse: 2.1501\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1499 - mse: 2.1499\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 773us/step - loss: 2.1498 - mse: 2.1498\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 2.1497 - mse: 2.1497\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 2.1496 - mse: 2.1496\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1494 - mse: 2.1494\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 2.1493 - mse: 2.1493\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1492 - mse: 2.1492\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 884us/step - loss: 2.1491 - mse: 2.1491\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1490 - mse: 2.1490\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1489 - mse: 2.1489\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1488 - mse: 2.1488\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1487 - mse: 2.1487\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 658us/step - loss: 2.1486 - mse: 2.1486\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1485 - mse: 2.1485\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1485 - mse: 2.1485\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1484 - mse: 2.1484\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1483 - mse: 2.1483\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 779us/step - loss: 2.1482 - mse: 2.1482\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1482 - mse: 2.1482\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1481 - mse: 2.1481\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 2.1480 - mse: 2.1480\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1480 - mse: 2.1480\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1479 - mse: 2.1479\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 698us/step - loss: 2.1478 - mse: 2.1478\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 782us/step - loss: 2.1478 - mse: 2.1478\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 2.1477 - mse: 2.1477\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1476 - mse: 2.1476\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1476 - mse: 2.1476\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1475 - mse: 2.1475\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 778us/step - loss: 2.1475 - mse: 2.1475\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1475 - mse: 2.1475\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1474 - mse: 2.1474\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 911us/step - loss: 2.1474 - mse: 2.1474\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 780us/step - loss: 2.1473 - mse: 2.1473\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 778us/step - loss: 2.1473 - mse: 2.1473\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 998us/step - loss: 2.1472 - mse: 2.1472\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1472 - mse: 2.1472\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 826us/step - loss: 2.1472 - mse: 2.1472\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1471 - mse: 2.1471\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 618us/step - loss: 2.1471 - mse: 2.1471\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 998us/step - loss: 2.1470 - mse: 2.1470\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1470 - mse: 2.1470\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 664us/step - loss: 2.1470 - mse: 2.1470\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 995us/step - loss: 2.1469 - mse: 2.1469\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 890us/step - loss: 2.1469 - mse: 2.1469\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 811us/step - loss: 2.1469 - mse: 2.1469\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1469 - mse: 2.1469\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 772us/step - loss: 2.1468 - mse: 2.1468\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1468 - mse: 2.1468\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1468 - mse: 2.1468\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1468 - mse: 2.1468\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 828us/step - loss: 2.1467 - mse: 2.1467\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 2.1467 - mse: 2.1467\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1467 - mse: 2.1467\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1467 - mse: 2.1467\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 747us/step - loss: 2.1466 - mse: 2.1466\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1466 - mse: 2.1466\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1466 - mse: 2.1466\n",
      "Epoch 172/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 887us/step - loss: 2.1466 - mse: 2.1466\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1466 - mse: 2.1466\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1465 - mse: 2.1465\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1465 - mse: 2.1465\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 663us/step - loss: 2.1465 - mse: 2.1465\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1465 - mse: 2.1465\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 553us/step - loss: 2.1465 - mse: 2.1465\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1465 - mse: 2.1465\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1464 - mse: 2.1464\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1464 - mse: 2.1464\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 885us/step - loss: 2.1464 - mse: 2.1464\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 774us/step - loss: 2.1464 - mse: 2.1464\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 638us/step - loss: 2.1464 - mse: 2.1464\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1464 - mse: 2.1464\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1464 - mse: 2.1464\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 742us/step - loss: 2.1464 - mse: 2.1464\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1463 - mse: 2.1463\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 644us/step - loss: 2.1463 - mse: 2.1463\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 770us/step - loss: 2.1463 - mse: 2.1463\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1463 - mse: 2.1463\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1463 - mse: 2.1463\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 2.1463 - mse: 2.1463\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1463 - mse: 2.1463\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1463 - mse: 2.1463\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1463 - mse: 2.1463\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1463 - mse: 2.1463\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 663us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 885us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 811us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 773us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 774us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 773us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 823us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 774us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 777us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 0s 885us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1462 - mse: 2.1462\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 890us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 774us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 0s 774us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 998us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 851us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 916us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 664us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 672us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 257/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 886us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 995us/step - loss: 2.1461 - mse: 2.1461\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 996us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 998us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 774us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 664us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 664us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 0s 890us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 774us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 770us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 779us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 774us/step - loss: 2.1460 - mse: 2.1460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x290b7536790>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=[1,2,3,4,5,6,7,8,9] # 공부하는 시간\n",
    "y=[11,22,33,44,53,66,77,87,95] # 각 공부하는 시간에 맵핑되는 성적\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 입력 x의 차원은 1, 출력 y의 차원도 1. 선형 회귀이므로 activation은 'linear'\n",
    "model.add(Dense(1, input_dim=1, activation='linear'))\n",
    "\n",
    "# sgd는 경사 하강법을 의미. 학습률(learning rate, lr)은 0.01.\n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "\n",
    "# 손실 함수(Loss function)은 평균제곱오차 mse를 사용합니다.\n",
    "model.compile(optimizer=sgd ,loss='mse',metrics=['mse'])\n",
    "\n",
    "# 주어진 X와 y데이터에 대해서 오차를 최소화하는 작업을 300번 시도합니다.\n",
    "model.fit(X,y, batch_size=1, epochs=300, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x290b90d22e0>,\n",
       " <matplotlib.lines.Line2D at 0x290b90d2550>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X, model.predict(X), 'b', X,y, 'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
